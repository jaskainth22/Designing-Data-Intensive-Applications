Distributed Data

Why do we want to Distribute data in different machines?
1. Scalability - If data volumne, read load or write load is much higher than a single machine can handle its good to Distribute it across multiple machines.
2. Fault tolernace/high availabiltiy - If Data is present in multiple machines if one machine goes down other can take over.
3. Latency - If our customers is across the globe, its good to get them the data from there nearest datacenter to reduce latency. Makes sense to have multiple data center distributed across the globe.

Scaling to higher load
Why to have multiple machines? Why not a single more powerful machine? (Vertical Scaling)
1. Cost is much higher (Load will not be handled as much as the cost is increased)
2. No fault tolernace - If this machine is down, we are screwed.

Another approach is shared disk approach
Meaning we will have multiple machines, but all the data will be stored in a single machines disks.
This will have further issues like locking limits the scalability

Shared nothing architecture (Horizontal scaling)
Each machine running the DB software is called a node. Each node uses its CPU, RAM and disk independently.


Replication vs Partitioning
There are 2 ways data is distributed across multiple nodes
Replication - Keeping a copy of same data on several different nodes. Provides redundancy.
Partitioning - Splitting a big DB into smaller subsets called partitions so that different partiotions can be assigned to different nodes.




===================
Chapter - 5
Replication

Replication means keeping the copy of same data on multiple machines

Advantages:
1. Keeping data geographically close to users (Reduce latency)
2. To allow system to continue working even if some parts have failed (increase avaibility)
3. Increase machines so that higher read throughout

If our data is not changing then replication is not an issue.
The issue arises when data keeps changing and all the machines must maintain the same data.
To resolve this we have 3 algos
    - Single leader
    - Multi leader
    - leaderless

Leaders and Followers
The most common way to maintain same data across multiple replicas is to have the master-slave config. All the writes will go to the master, master updates itself, sends a message to all the other replicas to update themselves. Read request can go to any replica.
So from users pespective we have only one write DB and multiple read DBs.

This is by default present in Most relational DBs (PostgreSQL, MySQL, SQL Server) and some NoSQL DBs (MongoDB).

Synchronus vs Asynschronus replication
In sync replication, Once a write is done on master, master send writes to its followers, as soon as one follower return success, the request will be success, We will not wait for other replicas success messages. So we should have atleast 1 sync replica and other can be async.
This ensures that we will always have atlest 1 follower who is in sync with the leader, so in case the leader goes down we can use the follower.
There is no point in waiting for all the followers, If we wait our request will get highly slow.

This config is called semi sync relication, in which we have 2 nodes with most recent data.

Often leader based replication is completely async. We do not wait for any followers success message.
This has the advantage that leader can continue processing write even if the followers are fallen behind. This can lead to durability issues as if the leader is down, we will lost the most recent writes, but still its a tradeoff most companies are willing to take.

==============================================
07/04/2025


Setting up new followers
If we want to add a new follower, we just simply cannot copy the data from leaders DB and put it in followers DB. The writes are continuous and they would not make sense, and we would lost the data. Other approach would be to lock the DB for writes and copy the data but this will lead to availability issues.
Best approach would be to take a snapshot of the leader DB at certain time, using that snapshot build the follower, and then have a list of the all the changes done at the leader after the snapshot is taken and update those changes in follower. Now the follower is in sync with leader.

Handling node outages
How can we hanlde node outages? What to do when one of the nodes is down, how to make sure that the whole system is running?

follower failure:
If one of the follower node is down, it can catchup quite easily. Each follower node has a log of all the changes that it received from leader. If the node crashes, it can easily rebuild itself using the logs. It can then ask the leader to send all the updates after it got crashed and then catch up with the leader.

leader failure: Failover
Leader is down, one of the follower is elected to be the new leader, CLients need to send writes to the new leader, The follower should start consuming writes from the new leader. This process is called Failover.

Failover can happen manually or automatically.
Manual failover steps:
1. Determining the leader has failed: We can use the timeout mechanism to detect this. Nodes keep sending messages to each other, if for a certain period of time we do not get a response back, we can tell that the node is down. 
2. Choosing a new leader: This is usually done by an election process where all the follower nodes choose there new leader. The best candiate would be who has the most up to date changes.
3. Reconfiguring the system to use the new leader: Clients now need to send the write requests to the new leader, other followers should start taking updates from this leader. If the original leader comes back up, it will still think that it is a leader, we need to make it a follower now.

Failover is a very error prone process, A lot of things can go wrong.
1. If async replication is used, the new leader may not have all the writes from the old leader. So what will we do? When the old leader comes back up it will have conflicting updates with the old leader. The best solution would be to discard the old leaders writes, but this will lead to durability issues.
2. Discarding writes is especially an issue when the other storage systems have the data present. For ex. In Github once a out of sync follower was made a leader. They have an autoincrementing counter for the primary key, due to this a wring counter was chosen as the primary key and writes are done. But there was also a Redis store which was using this primary key but it has the latest key from the old Leader, Due to this wring data is shown to certain users.
3. In certain fault scenarios, it could happen that we make 2 follower nodes as leaders, both these leaders start accepting writes, we will be in a sitation, where we have faulty writes. Best scenario would be to shutdown one leader node.
4. What is the right timeout before a leader is declared dead? Well this depends upon system to system. We should not have too smaller timeout as sometimes there are network problems or latency issues due to which we get delayed response, due to this we will have unnecessary failovers. 

Implementation of Replication logs
How does leader based replication works under the hood?

1. Statement based replication
    leader logs everything, and then send all the logs to followers. Suppose we have a relational DB, leader will log all the SQL queries and then send the exact same queries to followers. For followers this is very similar to getting requests from clients.
    But there are few issues in this approch
        - For functions like NOW() or rand() we will have different values in each replica
        - All the SQL queries should be done in the same order else we will have issues
    This type of approach is rarely used now a days as we have better appriaches.

WAL Shipping
As we saw in storage engines, In LSM trees we write the data in log files itself. In B-tress we first write data in WAL and then change the value in disk.
Using this log file we can regenerate the DB in case of a crash. We can use this exact same log file to build a replica on another node.
The WAL is at a very low level, it has info like which bytes got changed in DB. this makes replication strongly coupled with storage engine, We cannot have different types of DB for leader and follower.

Logical row based log repolication
In this type we do maintain a log but it will not have the low level details. This makes replciation independent from storage engine. 
We will store info at row based, For ex.
    - for an insertion, we will store which data is preset in each column,
    - for deletion we will store how to uniqely identify the row which got deleted
    - for update we will store the updated columns

With this we can have different versions of DBs running for leaders and followers, even we can have different types of storage engines.

Problems with Replication logs
The above leader based architecture works perfectly when our system has high reads. We just setup new followers so that read demands are fulfilled.
This works well only for async replication. For sync replication if one node goes down our entire system will be haulted during a write.
However we may see inconsistent results, our followers may not be up to date, due to which leader and follower will show different data. But if stop the writes, the follower will eventually catch up with the leader, this is known as eventual consistency.
This delay between the follower and leader is called replication lag. Usually it is of seconds, but sometimes it can be in minutes, this will lead to inconsistemt results.

======================================================
Issues due to replication lag

1. Reading your own writes - When user writes something in an appliocation, the write is sent to the leader and then the leader further sent the uodate to followers. But suppose in case of async replication, user asks for the data they wrote and the request went to the follower that is not yet updated, user will not get his data. THis functionality is not right.
We must gurantee read after write consostency. That is user must be able to read the data they write just after the operation is done even if the page is reloaded.
How can we implement read after write consistency?
    - If the user write very few data, send all the reads to the leader once the user write something. For ex. If only user can update his profile, then for profile reads we can send it to follower.
    - If the application allows multiple writes for any user, read from leader wont work as we will not have the benefit of mulitple read replicas. In that case we can have 1 min reads from leader and then from followers. 1 min is arbitraty if the replication lag is higher, this approach will again not work.
    - Clients can remember the timestamp of the write, and for the subsequent read the request should not go to any replica whose update is not present till that timestamp. Either the read can go to any other replica or should waut till the update is done.
    - Another issue is if user is using multiple devices, THen remembering this timestamp by client won't work, this need to be centralized.
    - If the users are on different networks, using the leader approach also won't work as the requests can got to different datacenters.

2. Monotonic Reads - User should go back in time. Meaning? If we make consecutive read requests, user should always see the same result. It should not happen that for one request it sees the latest data and for other request it sees past data (as the follower is not catched up).
Monotonic reads does not gurantee string consistency but it guranteees more than eventual consistency. 
For this to work all the read requests for one user should go to the same follower. We can use some hashId to determine which users requests go to which server, However if the server fails, requests will go to different server.

3. Consistent prefix reads - If multiple writes are happening, then reads should also happen in the same order. We should not see a write which happens later before a write which happened before. This is particuarly an issue in sharded DBs. Sharded DBs operate independently. So its hard.
What we can do is for one user all the writes should go to one shard.

Multileader replication
Having multiple leaders who accept writes, each leader will act as a follower for another leader.

Where exatly can we use Multileader replication?
1. MultiData center - Normally in a multidatacenter if we have a single leader, it will be present in any one datacenter. It will then update all the followers in all the datacenters. This can be time consuming as data centers can be very far away and we need to send these updates over public network. Within a datacenter sending updates are fast as we use private network. In a multileader config, we have 1 leader in each datacenter, each leader can accept a write, once a write is done, it will send updates to each leader in other datacneters, they will then further update there followers.
There is one issue, if there is a concurrent write on same data in two different datacenters, we need to do conflict resolution.

2. Clients with offline operation - Consider the calendar app, we can view and write meeting in the calendar app even if its offline. When it gets internt connection, we need to send these updates to the other devices. So each device have a local leader which do all the writes, once it gets internet connection, it sends all the updates/writes to other clients. Here each client is a datacenter and there is very big network outages between them.

3. Collabrative editing - Consider Google docs, multiple people can edit at the same time. Same situation in case of DBs. Mutiple leaders writing at the same time. This can lead to serious conflict resolution issues.

Hadling write conflicts
As discussed the biggest problem in Multi leader replication is conflict resolution, if 2 leaders concurrently update the same data, we will have an issue.
 - In a single leader, we would never have this issue. If 2 users want to write the data, the other user cannot write as the leader is already processing another request. The problem with multi leader will be detected very later in the futute in async replication. In sync replication, we can wait for the write operation till the data is updated in all replicas, we will detect the conflict there only but what is the point of having multiple leaders if are still waiting.

Conflict avoidance - This strategy suggests that for a particular record, all the reads and writes should go to the same dataceter (leader).  With this we can avoid the concurrent siutation as the writes will go to the same node. However this will become ineffective if the datacenter goes down, then we need to use some other leader.

Converging towards a consistent state
If we are having 2 different values for the same data due to concurrent writes by 2 leaders, we should resolve this and get towards a consistent state,
 - either use a GUID/timestamp with each write operation and let the bigger value be the final, but this will lead to data loss.
 - Have a no. for each replica, and the replica with bigger no. have the final value, still a bad approach and lead to data loss.
 - Let the application code handle it by asking the user. User should decide which value to choose. 


===================================
09/04/2025

Custom conflict resolution logic
We can add the conflict resolution logic in applicatipon code. 
On write - As soon as write is done and we detect a conflict, code should run to resolve that conflict
On read - When the next read is done and conflict apperars, either we let the user resolve the conflict or do it automatically. Cockroach DB does this.

Automatic conflict resolution
There are certain algorithms that have been introduced to do this. Certain datatypes/data structures are designed to handle concurrent editing. 


Another ex. of conflicts is consider a meeting room booking system. Suppose 2 different people book meeting concurrently for the same time and the req went to two different leaders. In later parts of the book we will see how ton better resolve these issues. 


Multi leader replication toplogies
All to All - Each leader will send the writes to all other leaders
Circular - One leader will send writes to the other leader, the second leader along with the writes from first and its own, send it to the next and so on. THis moves in a circular fashion.
Star - A node is present in the center, and it sends update to all the nodes around it. 

All to All is the most preferrable one. In Circular and Star if one node fails it will stop the replication process for all the other nodes as well. 
However there are issues with All to All as well. Suppose L1 sends writes to all L2, L3 and L4. It reaches in time to L2 and L3, But before it reaches L4, another write is done by L3 on the same data, and that reaches L4 before the write from L1. THis is the same issue as in concurrent read prefix. We need to carefully design our systems and handle these problems.

Leaderless replication
Unlike leader and multi leader approach, in this the write request go to any arbitrary node. Sometimes the client sends the request to all the nodes parallely.
Dynamo Amazon's Inhouse datastore uses this approach. This is not DynamoDB.
Suppose client sends a write requests to all the replicas, R1, R2, R3. R1 and R2 acknowldeged the write but R3 was down at that time. Suppose if our writes are deisgned in such a way that we got OK from more than 50% the requests are Good. R3 is still having old data.
Now for the read the req. again go to all the replicas. R1 and R2 gives latest data and R3 gives old data.
We can use Version numbers to resolve this issues.

================================
12-04-2025


How to ensure latest data is getting copied in all replicas?
1. On Read - Since client sends read request to all the replicas, it can detect which replicas are left behind. It then sends update request in those replicas.
2. Process - A process keeps running, which will detect all the replicas which are left behind. And sends update to those replicas.

Quorum consensus
If there are n replicas, We must have a successfull writes in at least w replicas and we must send read request to at least r replicas.
 w+r > n
These are quorum reads and writes. 

W = No. of replicas that must agree for a write (wait for acknowledgement from w nodes before confirming write success)
R = We sends read request to all n nodes, r nodes must acknowledge the request. We get the data from r nodes and compare there versions and return latest one.


Normally reads and writes are sent to all the replicas in parallel, w and r determines how many nodes we wait for a success.

ex. n=5, w=3, r=3 We can toleratre 2 nodes to be down. We require acknowldegement from 3 nodes for each read and write operation.
If fewer than w or r nodes returns a success, we fail the operation. 

For read heavy and limited writes system, we can keep R=1 and W=n. This will make reads faster. But even if a single node is down, our write operation will be unsuccesfull.

If w+r > n, this ensures that our every read will be latest. Bcz atleadt one node will overlap between the read and write request.

If we keep w+r <= n, this ensures low latency and high availability, But we are not sure if our reads will give us the same data. Its possible that reads return stale data, as no node is overlapping between the read and write requests.

There are some edge cases where w+r > n still return stale values.
    - If two writes happen concurrently, its not clear which happended first. We need to keep only the latest or one configured based on conflict resolution algo. This will lead to lost write and there may be not overlap anymore.
    - If read and write happen concurrently. We may get stale data.
    - If write failed on some replicas and we have fewer than w replicas, the operation is failed. If we do not roll back on the succeeded replias, this will  be discrepancy.
    - If a node carrying latest data crashed,  we may have fewer than w nodes with latest data breaking the quorum.

Monitorning stalelessness
In replicated environments, we need to keep track how far is a node. Or how much is the replication lag. In leader based architecture its easy, as we have a leader and we can detect the lag for the followers. If some nodes are too far behind we need to investigate.
However in leaderless replication, its difficult to monitor. Why? Bcz writes are not fixed, and if we are just using read repair for replicating latest data, the lag can be huge.


Sloppy Quorums and Hinted Handoff
In leaderless replication, if quorums are set correctlty, we don;t need to do failover for a node that went down as out system will keep on working if we have atleadt w and r nodes availble. Also we don't need to wait for slower nodes to process data, as we just need confuramtion from w or r nodes. This makes it very low latency and highly availble, and fault tolerant.

Suppose one of our clients lost connection with most of the nodes (within the n nodes). For the client now it cannot do any read or write operation as the w or r are not matched. A quorum is not reached.
But suppose in the system there are orther nodes as well (apart from these n nodes). TO these nodes the client can connect.
SO what should we do in this scenario?
Should we just return an error for the write request as w is not matched?
Or should we use the nodes from other than these n nodes? (As with them w is matched).
Well this is called sloppy quorums. We will write the data temporarily to these other nodes and once we establish a connection with the original nodes (n nodes), we transfer this data to them. This transfer pricess is called hinted handoff.
This ensures that our system is availble for the write operations. High write availability.

Cassandra, Voldmort, Azure Cosmos DB all follow leaderless replication.

MultiData center operation - Leaderless replication, is useful in multidata center replication as wll. In some DBs which uses leaderless replication, the n nodes are present in multiple data centers. In some DBs, the n nodes are within a single data center and the replication to other datacenters happens async

Detecting Concurrent writes
In leaderless replication also we have the same issue of concurrent writes. Multiple client can write the same key in multiple nodes, leading to conflicts. We must resolve these conflicts and all the nodes should have the same data. We should reach towards a consistent state.

Now how to resolve these conflict resolutions? We saw some techniques earlier in leader based replication, let see few more.

1. Last write wins (discarding concurrent writes)
    This means that with each write we should attach a timestamp, And if there is a conflict the newer write should be kept and all the older one is discarded. This is followed in Cassandra. But in this approch we have data loss, we have durability issues. If we dont; want our data to lose this is a poor choice. 
    This is useful in DBs where keys are immutable that means once written the keys will not change. In cassandra the recommended way to write is having a unique UUIDs as keys.

What operations are called concurrent? 
    Well in theory it means that two operations occuring at the same time. Well this is very rare. In CS we say that 2 operations are concurrent when these two operations don;t know aything about each other.
    For ex. Suppose operation A happens operation B, HOW? Operation B knows about the existence of operation A. Two operations are concurrent if they don;t know anything about each other. Its possiblt that the timestamps are different but still they are concurrent.


Version vectors
Version vectors are used to identify concurrent updates and do conflict resolution.
Each node maintains a version vector for each key. Suppose two replicas are there and both can do write operation.
Both maintains versoin vectors.

Intially version vector for a key is [0,0]
Node A updates the key and add PS5, the VV becomes [1,0] | [PS5]
Node B without the knowledge of this update by A, add XBox, The version vector becomes [0,1] | [XBOX].

These version vectors along with the value added to the key are sent to the client. Now Node A, adds another item to the key, Monitor. Since
its version vector wa [1,0] | [PS5] it adds Monitor to the list and increment the version vector [2,0] | [ps5, monitor].
Now when the changes are replicated to each replica, there is definitely a conflict. 
Node A has version vector [2,0], and node B has version vector [0,1].
Now for resolving the conflict we will create another version vector [2,1]. It will have the values from both replicas as seperate lists.
[2,1] | [ps5, monitor] | [xbox]

Either we can merge these 2 lists, or show user that these 2 lists are there, resolve the conflict yourself.


Or we can use CRDTs (Conflict resolution data types). these will resolve conflicts automatically.

